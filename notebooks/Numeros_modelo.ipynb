{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importaciones"
      ],
      "metadata": {
        "id": "CkxvATnDgjQb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install tensorflow gdown --quiet"
      ],
      "metadata": {
        "id": "TenRPCNE689A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSaZd8A7VKQp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab import files\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de estructura y Particiones"
      ],
      "metadata": {
        "id": "QGPB1nom3nIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = './data/dataset.zip'\n",
        "url = 'https://drive.google.com/uc?id=1vOafMTcq3i_SzexClnkEfv0HfLPuh-Zz'\n",
        "\n",
        "# Crear carpeta data\n",
        "os.makedirs('./data', exist_ok=True)\n",
        "\n",
        "# Descargar el dataset\n",
        "gdown.download(url, zip_path, quiet=False)\n",
        "print(\"Descarga completada, descomprimiendo...\")\n",
        "\n",
        "# Descomprimir\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('./data/')\n",
        "os.remove(zip_path)  # Borrar el zip después de extraer\n",
        "print(\"Dataset descomprimido correctamente.\")"
      ],
      "metadata": {
        "id": "QzZO-WeZWfdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_imagenes = \"./data/Sign Language Dataset\"\n",
        "\n",
        "# Lista donde almacenaremos la ruta de cada imagen y su etiqueta\n",
        "datos = []\n",
        "# Extensiones válidas para considerar un archivo como imagen\n",
        "extensiones_permitidas = ('.jpg', '.jpeg', '.png', '.bmp')\n",
        "\n",
        "# Recorremos cada subcarpeta dentro de la carpeta principal (cada subcarpeta es una clase)\n",
        "for clase in os.listdir(ruta_imagenes):\n",
        "    ruta_clase = os.path.join(ruta_imagenes, clase) # Ruta completa a la carpeta de la clase\n",
        "    if os.path.isdir(ruta_clase):\n",
        "        # Recorremos los archivos dentro de esa clase\n",
        "        for archivo in os.listdir(ruta_clase):\n",
        "            # Verificamos que el archivo sea una imagen\n",
        "            if archivo.lower().endswith(extensiones_permitidas):\n",
        "                # Añadimos un diccionario con la ruta completa y su etiqueta\n",
        "                datos.append({\n",
        "                    'filename': os.path.join(ruta_clase, archivo),\n",
        "                    'class': clase\n",
        "                })\n",
        "\n",
        "# Si no se encontraron imágenes, mostramos un error\n",
        "if not datos:\n",
        "    raise ValueError(\"No se encontraron imágenes en el dataset. Verifica la ruta.\")"
      ],
      "metadata": {
        "id": "pINLhDX4X3PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertir a DataFrame\n",
        "df = pd.DataFrame(datos)\n",
        "\n",
        "# Dividir en train, val y test\n",
        "df_train_val, df_test = train_test_split(df, test_size=0.05, stratify=df['class'], random_state=42)\n",
        "df_train, df_val = train_test_split(df_train_val, test_size=0.20, stratify=df_train_val['class'], random_state=42)\n",
        "\n",
        "# Verificación del tamaño de las divisiones\n",
        "print(f'Tamaño entrenamiento: {len(df_train)}')\n",
        "print(f'Tamaño validación: {len(df_val)}')\n",
        "print(f'Tamaño test: {len(df_test)}')"
      ],
      "metadata": {
        "id": "LA_UNZuuavsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Crear generadores"
      ],
      "metadata": {
        "id": "QHmsY74pgaUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(rescale=1./255)    # Normalizar imágenes al rango [0,1]\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    df_train,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(100, 100),   # Redimensionar todas las imágenes a 100x100\n",
        "    color_mode='grayscale',   # Convertir a escala de grises (1 canal)\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',   # Etiquetas one-hot para clasificación multiclase\n",
        "    shuffle=True,   # Barajar imágenes para entrenamiento\n",
        "    seed=42   # Semilla para reproducibilidad\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    df_val,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(100, 100),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False   # Mantener el orden fijo para validación\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    df_test,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(100, 100),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False   # Mantener el orden fijo para test\n",
        ")"
      ],
      "metadata": {
        "id": "BCcFNenlcCP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mostrar ejemplo"
      ],
      "metadata": {
        "id": "dsoPDiRpJEFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Obtener un lote del generador\n",
        "x_batch, _ = next(train_generator)  # Ignoramos las etiquetas\n",
        "\n",
        "# Tomar la primera imagen del batch\n",
        "img = x_batch[0]  # Imagen redimensionada y normalizada\n",
        "\n",
        "# Mostrar la imagen\n",
        "plt.imshow(img.squeeze(), cmap='gray')  # squeeze para quitar el canal extra\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QDrkEq3ljlAo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.squeeze())  # Mostrar la matriz 100x100"
      ],
      "metadata": {
        "id": "_WrWqYdPjrmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de la Primera Red Neuronal"
      ],
      "metadata": {
        "id": "c5qhQ9lilifi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La Red Neuronal contará con dos capas convolucionales y una capa densa."
      ],
      "metadata": {
        "id": "ehOOQy9Slt9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# Primera capa convolucional\n",
        "model.add(Conv2D(32, (3,3), activation='relu', input_shape=(100,100,1))) # 32 filtros, kernel de 3x3, función activación relu, 100x100 pixeles, 1 Canal\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "# Segunda capa convolucional\n",
        "model.add(Conv2D(64, (3,3), activation='relu')) # 64 filtros\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "\n",
        "# Aplanar para pasar a la capa densa\n",
        "model.add(Flatten())\n",
        "\n",
        "# Capa densa totalmente conectada\n",
        "model.add(Dense(128, activation='relu')) # 128 neuronas\n",
        "model.add(Dropout(0.5))  # Evitar overfitting\n",
        "\n",
        "# Capa de salida (10 clases)\n",
        "model.add(Dense(10, activation='softmax')) # Una neurona por cada clase"
      ],
      "metadata": {
        "id": "pI_k4vy3lDkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001), # Optimizador\n",
        "    loss='categorical_crossentropy', # Función de perdida\n",
        "    metrics=['accuracy'] # Medir accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "4BFbFzjEou0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamos el modelo\n",
        "history = model.fit(\n",
        "    train_generator,  # Generador de entrenamiento\n",
        "    epochs=20,  # Número de épocas\n",
        "    validation_data=val_generator,  # Generador de validación\n",
        "    verbose=2\n",
        "    )"
      ],
      "metadata": {
        "collapsed": true,
        "id": "wEkgcfTPpkAo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualización Resultados: Primera Red Neuronal"
      ],
      "metadata": {
        "id": "4pQdhtkEHqRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Accuracy\n",
        "plt.plot(history.history['accuracy'], label='Accuracy Entrenamiento')\n",
        "plt.plot(history.history['val_accuracy'], label='Accuracy Validación')\n",
        "\n",
        "plt.title('Precisión durante el primer entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Valor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1PQlR9U3tEOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Loss\n",
        "plt.plot(history.history['loss'], label='Loss Entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Loss Validación')\n",
        "\n",
        "plt.title('Error durante el primer entrenamiento')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Valor')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8N3ZRB_mu8oC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar todo el modelo (arquitectura + pesos + optimizer)\n",
        "model.save(\"sign_language_model.h5\")\n",
        "print(\"Modelo guardado como sign_language_model.h5\")\n",
        "\n",
        "files.download(\"sign_language_model.h5\")"
      ],
      "metadata": {
        "id": "9fj-aaUVvpvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Metricas de Rendimiento: Primera Red Neuronal"
      ],
      "metadata": {
        "id": "n0D3aTf5wiMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones del conjunto de validación\n",
        "y_prob = model.predict(val_generator, steps=len(val_generator), verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1) # Índice de la clase predicha\n",
        "y_true = val_generator.classes # Clases reales\n",
        "labels = list(val_generator.class_indices.keys()) # Nombres de las clases\n",
        "\n",
        "# Reporte de clasificación\n",
        "print(\"\\nReporte de clasificación Primer Modelo:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "9xfSoa9wwKN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Etiqueta real\")\n",
        "plt.title(\"Matriz de Confusión Primer Modelo\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "swuJJA-TxGJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creación de la Segunda Red Neuronal"
      ],
      "metadata": {
        "id": "K2bPEfArzwvM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como los resultados del Primer Modelo no han sido los deseados, seguramente debido a la simplicidad de la arquitectura del mismo, ahora vamos a probar con un modelo más sofísticado.\n",
        "\n",
        "Este nuevo modelo implementado corresponde a una arquitectura CNN profunda de tipo **VGG-like**, estructurada en varios bloques convolucionales seguidos de una capa densa para la clasificación, lo que permite una buena extracción de características y un rendimiento sólido en el reconocimiento de imágenes."
      ],
      "metadata": {
        "id": "ENQvzyBtLDSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_cnn = Sequential()\n",
        "\n",
        "# Bloque 1\n",
        "model_cnn.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(100,100,1)))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(MaxPooling2D((2,2)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "\n",
        "# Bloque 2\n",
        "model_cnn.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(MaxPooling2D((2,2)))\n",
        "model_cnn.add(Dropout(0.25))\n",
        "\n",
        "# Bloque 3\n",
        "model_cnn.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(MaxPooling2D((2,2)))\n",
        "model_cnn.add(Dropout(0.30))\n",
        "\n",
        "# Clasificación\n",
        "model_cnn.add(Flatten())\n",
        "model_cnn.add(Dense(256, activation='relu'))\n",
        "model_cnn.add(Dropout(0.5))\n",
        "model_cnn.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model_cnn.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "hRdyBOaNHeWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mejoras de este Nuevo Modelo con respecto al Primer Modelo:\n",
        "\n",
        "- Modelo mucho más profundo → con más capas convolucionales y más filtros el modelo puede aprender patrones más complejos (dedos, forma de la mano) y distinguir clases muy similares.\n",
        "\n",
        "- BatchNormalization → normaliza la salida de cada capa para que el entrenamiento sea más estable y rápido.\n",
        "\n",
        "- Dropout al final de cada bloque → apaga aleatoriamente neuronas durante el entrenamiento, evitando que el modelo memorice posturas concretas y falle cuando cambia la mano.\n",
        "\n",
        "- Data augmentation fuerte → genera múltiples versiones de cada imagen, simulando variaciones reales provocando que el modelo se vuelva resistente a cambios de ángulo, escala o iluminación.\n",
        "\n",
        "- Clasificador final más potente → Flatten + Dense 256 combina todas las características extraídas por las convoluciones dandole al modelo la capacidad para discriminar mejor entre clases visualmente parecidas.\n",
        "\n",
        "- Learning rate más bajo (0.0005) → evita que la red se pase del mínimo local y ayuda a afinar detalles, importante con imágenes difíciles.\n",
        "\n",
        "- Implementacion de Callbacks: Se añadieron varios callbacks que optimizan el proceso de entrenamiento haciendo que este sea más lo más estable, más corto, y nos dé el modelo con mejor capacidad de generalización."
      ],
      "metadata": {
        "id": "eH46I9owKAg5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generador de entrenamiento con data augmentation ---\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,      # rota las imágenes hasta ±15 grados\n",
        "    width_shift_range=0.10, # desplaza horizontalmente hasta 10%\n",
        "    height_shift_range=0.10,# desplaza verticalmente hasta 10%\n",
        "    zoom_range=0.10,        # aplica zoom aleatorio hasta ±10%\n",
        "    shear_range=0.10        # aplica deformación tipo “cizalla” hasta 10%\n",
        ").flow_from_dataframe(\n",
        "    df_train,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=(100,100),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=20,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")"
      ],
      "metadata": {
        "id": "nE9hg0gSGmLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Callbacks de la Segunda Red Neuronal:\n",
        "\n",
        "- EarlyStopping → detiene el entrenamiento automáticamente si el modelo deja de mejorar en validación, evitando sobreajuste y ahorrando tiempo.\n",
        "\n",
        "- ReduceLROnPlateau → si el modelo se estanca, reduce la tasa de aprendizaje a la mitad, lo que permite afinar la red y mejorar precisión en clases difíciles.\n",
        "\n",
        "- ModelCheckpoint → guarda el mejor modelo durante el entrenamiento para no perder los pesos óptimos."
      ],
      "metadata": {
        "id": "BcLfRzVyLUkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Callbacks ---\n",
        "callbacks = [\n",
        "    # Detiene el entrenamiento si la pérdida de validación no mejora durante 6 épocas\n",
        "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True, verbose=1),\n",
        "\n",
        "    # Reduce la tasa de aprendizaje si la pérdida de validación se estanca durante 4 épocas\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
        "\n",
        "    # Guarda automáticamente el modelo con menor pérdida de validación\n",
        "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "fP02CTQHKMBO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrenamiento Segunda Red Neuronal"
      ],
      "metadata": {
        "id": "KIwTCgpSEfye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "h3ekOCleQ-go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga los pesos guardado del entrenamiento\n",
        "model_cnn.load_weights(\"model_cnn_bloque2_20.weights.h5\")"
      ],
      "metadata": {
        "id": "dEsicbqmRBaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso este Nuevo Modelo lo entrenaremos con un Epochs=28"
      ],
      "metadata": {
        "id": "yBQMr65EN0Fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Entrenamiento ---\n",
        "history = model_cnn.fit(\n",
        "    train_generator,\n",
        "    epochs=28,              # máximo número de épocas\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "7UTQzvLvZrsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar PESOS del Modelo\n",
        "model_cnn.save_weights(\"model_cnn_numeros.weights.h5\")\n",
        "print(\"Pesos guardados como model_cnn_numeros.weights.h5\")\n",
        "\n",
        "files.download(\"model_cnn_numeros.weights.h5\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "744gdYnjATGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluación en Test"
      ],
      "metadata": {
        "id": "1uggtWKKGjS_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_cnn.evaluate(test_generator, verbose=2)\n",
        "print(f\"Precisión en test: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "6h7fn43rCCcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones del conjunto de test\n",
        "y_prob = model_cnn.predict(test_generator, steps=len(test_generator), verbose=0)\n",
        "y_pred = np.argmax(y_prob, axis=1)  # Índice de la clase predicha\n",
        "y_true = test_generator.classes     # Clases reales\n",
        "labels = list(test_generator.class_indices.keys())  # Nombres de las clases\n",
        "\n",
        "# Reporte de clasificación\n",
        "print(\"\\nReporte de clasificación Segundo Modelo:\\n\")\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ],
      "metadata": {
        "id": "NvPa-ibkCD2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz de confusión\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Visualización\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicción\")\n",
        "plt.ylabel(\"Etiqueta real\")\n",
        "plt.title(\"Matriz de Confusión Segundo Modelo\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENuga7qhCxHI",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Serialización del Modelo"
      ],
      "metadata": {
        "id": "0HarYXpqx7w6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Guardar TODO el Modelo (arquitectura + pesos + optimizer)\n",
        "model_cnn.save(\"model_cnn_numeros.h5\")\n",
        "print(\"Modelo guardado como model_cnn_numeros.h5\")\n",
        "\n",
        "files.download(\"model_cnn_numeros.h5\")"
      ],
      "metadata": {
        "id": "KK7s5FKkETdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar el Modelo"
      ],
      "metadata": {
        "id": "bvNk5PUxyJ96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://drive.google.com/uc?id=1JmfrhsnctvXNG4DI0Ik8QuKA0JG5Ay7X'\n",
        "output = \"model_cnn_cargado.h5\"\n",
        "gdown.download(url, output, quiet=False)\n",
        "model_cnn = load_model(output)\n",
        "print(\"Modelo cargado correctamente.\")"
      ],
      "metadata": {
        "id": "M4uAkQzhytaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model_cnn.evaluate(test_generator, verbose=2)\n",
        "print(f\"Precisión en test: {test_acc:.2f}\")"
      ],
      "metadata": {
        "id": "ncpigA_N3hAE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}